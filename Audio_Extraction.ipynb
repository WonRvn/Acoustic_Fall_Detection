{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mono Audio Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wonha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Audio_Files/Fall_Mono'\n",
    "file_aug_path = 'Aug_Audio_Files/Aug_Fall_Mono'\n",
    "output_path = 'Mono_Audio_Feature/Fall_Feature'\n",
    "count = 1\n",
    "\n",
    "fall_list = [file_name for file_name in os.listdir(file_path) if file_name.endswith('.wav')]\n",
    "aug_list = [file_name for file_name in os.listdir(file_aug_path) if file_name.endswith('.wav')]\n",
    "\n",
    "for file_name in fall_list + aug_list:\n",
    "    if file_name.endswith('.wav'):\n",
    "        if file_name in fall_list:\n",
    "            full_file_name = os.path.join(file_path, file_name)\n",
    "        else:\n",
    "            full_file_name = os.path.join(file_aug_path, file_name)\n",
    "\n",
    "        output_file_name = os.path.join(output_path, f'F{count}.csv')\n",
    "\n",
    "        y, sr = librosa.load(full_file_name)\n",
    "        duration = librosa.get_duration(y=y)\n",
    "        onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=2205, aggregate=np.median)\n",
    "\n",
    "        df = pd.DataFrame(onset_env)\n",
    "        df.to_csv(output_file_name)\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Audio_Files/Non_Fall_Mono'\n",
    "file_aug_path = 'Aug_Audio_Files/Aug_NonFall_Mono'\n",
    "output_path = 'Mono_Audio_Feature/Non_Fall_Feature'\n",
    "count = 1\n",
    "\n",
    "non_fall_list = os.listdir(file_path)\n",
    "non_aug_list = [file_name for file_name in os.listdir(file_aug_path) if file_name.endswith('.wav')]\n",
    "\n",
    "for file_name in non_fall_list + non_aug_list:\n",
    "    if file_name.endswith('.wav'):\n",
    "        if file_name in non_fall_list:\n",
    "            full_file_name = os.path.join(file_path, file_name)\n",
    "        else:\n",
    "            full_file_name = os.path.join(file_aug_path, file_name)\n",
    "\n",
    "        output_file_name = os.path.join(output_path, f'NF{count}.csv')\n",
    "\n",
    "        y, sr = librosa.load(full_file_name)\n",
    "        duration = librosa.get_duration(y=y)\n",
    "        onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=2205, aggregate=np.median)\n",
    "\n",
    "        df = pd.DataFrame(onset_env)\n",
    "        df.to_csv(output_file_name)\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the second column from CSV files in a directory\n",
    "def read_second_column_csv(directory):\n",
    "    dataframes = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(directory, filename), header=None, usecols=[1])\n",
    "            flattened_df = df.T\n",
    "            dataframes.append(flattened_df)\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# # Function to apply various augmentations to audio data\n",
    "# def augment_audio_data(y, sr, augmentations):\n",
    "#     augmented_data = []\n",
    "#     audio = AudioSegment(y, frame_rate=sr)\n",
    "#     for aug in augmentations:\n",
    "#         if aug == 'noise':\n",
    "#             noise = AudioSegment.from_mono_audioarrays(np.random.normal(size=y.shape[0]), sr)\n",
    "#             y_aug = audio.overlay(noise)\n",
    "#         elif aug == 'shift':\n",
    "#             shift_range = int(np.random.uniform(low=-5, high=5) * sr)\n",
    "#             y_aug = audio[shift_range:] + audio[:shift_range]\n",
    "#         elif aug == 'stretch':\n",
    "#             rate = np.random.uniform(low=0.8, high=1.2)\n",
    "#             y_aug = librosa.effects.time_stretch(y, rate=rate)\n",
    "#         elif aug == 'pitch':\n",
    "#             n_steps = np.random.uniform(low=-1, high=1)\n",
    "#             y_aug = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)\n",
    "#         elif aug == 'reverb':\n",
    "#             y_aug = AudioSegment.from_mono_audioarray(y, sr)\n",
    "#             y_aug = y_aug + y_aug.reverse()\n",
    "#         elif aug == 'speed':\n",
    "#             speed_rate = np.random.uniform(low=0.7, high=1.3)\n",
    "#             y_aug = librosa.effects.time_stretch(y, speed_rate)\n",
    "#         elif aug == 'change_volume':\n",
    "#             change_in_dBFS = np.random.uniform(low=-10.0, high=10.0)\n",
    "#             y_aug = AudioSegment.from_mono_audioarray(y, sr)\n",
    "#             y_aug = y_aug + change_in_dBFS\n",
    "#         augmented_data.append(y_aug)\n",
    "#     return augmented_data\n",
    "\n",
    "\n",
    "# # # Function to add augmentations to a dataset\n",
    "# # def add_augmentations_fall(directory, sr=16000, augmentations=['shift'], repeats=10):\n",
    "# #     augmented_dataframes = []\n",
    "# #     for filename in os.listdir(directory):\n",
    "# #         if filename.endswith('.csv'):\n",
    "# #             df = pd.read_csv(os.path.join(directory, filename), header=None, usecols=[1])\n",
    "# #             y = df.iloc[:, 0].values\n",
    "# #             for _ in range(repeats):  # Repeat the augmentations\n",
    "# #                 augmented_clips = augment_audio_data(y, sr, augmentations)\n",
    "# #                 for aug_clip in augmented_clips:\n",
    "# #                     aug_features = librosa.feature.mfcc(y=aug_clip, sr=sr, n_mfcc=13)\n",
    "# #                     flattened_features = np.mean(aug_features, axis=1).reshape(1, -1)\n",
    "# #                     augmented_dataframes.append(pd.DataFrame(flattened_features))\n",
    "# #     return pd.concat(augmented_dataframes, ignore_index=True)\n",
    "    \n",
    "\n",
    "# # Function to add augmentations to a dataset\n",
    "# def add_augmentations_non_fall(directory, sr=16000, augmentations=['noise', 'shift', 'stretch', 'pitch', 'reverb', 'speed', 'change_volume'], repeats=10):\n",
    "#     augmented_dataframes = []\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith('.csv'):\n",
    "#             df = pd.read_csv(os.path.join(directory, filename), header=None, usecols=[1])\n",
    "#             y = df.iloc[:, 0].values\n",
    "#             for _ in range(repeats):  # Repeat the augmentations\n",
    "#                 augmented_clips = augment_audio_data(y, sr, augmentations)\n",
    "#                 for aug_clip in augmented_clips:\n",
    "#                     aug_features = librosa.feature.mfcc(y=aug_clip, sr=sr, n_mfcc=13)\n",
    "#                     flattened_features = np.mean(aug_features, axis=1).reshape(1, -1)\n",
    "#                     augmented_dataframes.append(pd.DataFrame(flattened_features))\n",
    "#     return pd.concat(augmented_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# from imblearn.over_sampling import KMeansSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_dir = 'Mono_Audio_Feature/Fall_Feature'\n",
    "non_fall_dir = 'Mono_Audio_Feature/Non_Fall_Feature/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wonha\\AppData\\Local\\Temp\\ipykernel_8148\\3945667536.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data['label'] = [1] * len(falls_data) + [0] * len(not_falls_data)\n"
     ]
    }
   ],
   "source": [
    "# Read and combine CSV files\n",
    "falls_data = read_second_column_csv(fall_dir)\n",
    "not_falls_data = read_second_column_csv(non_fall_dir)\n",
    "\n",
    "# # Apply augmentations\n",
    "# # falls_augmented_data = add_augmentations_fall(fall_dir)\n",
    "# not_falls_augmented_data = add_augmentations_non_fall(non_fall_dir)\n",
    "\n",
    "# Combine original and augmented data\n",
    "# combined_data = pd.concat([falls_data, not_falls_data, falls_augmented_data, not_falls_augmented_data])\n",
    "combined_data = pd.concat([falls_data, not_falls_data])\n",
    "combined_data['label'] = [1] * len(falls_data) + [0] * len(not_falls_data)\n",
    "                        #  [0] * len(not_falls_augmented_data)\n",
    "                        #  [1] * len(falls_augmented_data) + [0] * len(not_falls_augmented_data)\n",
    "\n",
    "# outliers = detect_outliers_iqr(combined_data)\n",
    "# combined_data[outliers] = np.nan\n",
    "\n",
    "# Apply K-Means SMOTE for balancing\n",
    "# kmeans_smote = KMeansSMOTE(random_state=123, k_neighbors=10, cluster_balance_threshold=0.1)\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "X = X.fillna(0)\n",
    "# X_resampled, y_resampled = kmeans_smote.fit_resample(X, y)\n",
    "\n",
    "# Combine resampled features and labels into a DataFrame\n",
    "resampled_data = pd.DataFrame(X, columns=X.columns)\n",
    "resampled_data['label'] = y\n",
    "\n",
    "# Shuffle the dataset\n",
    "resampled_data = resampled_data.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# Separate the dataset by label\n",
    "falls_data_label = resampled_data[resampled_data['label'] == 1]\n",
    "not_falls_data_label = resampled_data[resampled_data['label'] == 0]\n",
    "\n",
    "# # Sample 350 entries from each subset\n",
    "# sampled_falls_data = falls_data_label.sample(n=1200, random_state=123).reset_index(drop=True)\n",
    "# sampled_not_falls_data = not_falls_data_label.sample(n=1200, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# Combine the sampled data\n",
    "combined_sampled_data = pd.concat([falls_data_label, not_falls_data_label]).reset_index(drop=True)\n",
    "\n",
    "# Shuffle the combined sampled dataset\n",
    "semi_sampled_data = combined_sampled_data.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "semi_sampled_data.to_csv('semi_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387220</td>\n",
       "      <td>1.469951</td>\n",
       "      <td>0.848093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.402276</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.719712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.078666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.116067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266676</td>\n",
       "      <td>0.435027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149434</td>\n",
       "      <td>0.030668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.917328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.864935</td>\n",
       "      <td>0.488492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844417</td>\n",
       "      <td>0.536116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125597</td>\n",
       "      <td>0.048152</td>\n",
       "      <td>0.245986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073176</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.337677</td>\n",
       "      <td>0.293424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.872908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.151660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.656493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.190015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.641998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.938718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 249 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1         2         3         4         5         6          7  \\\n",
       "0     0.0  0.0  0.387220  1.469951  0.848093  0.000000  0.407553   0.000000   \n",
       "1     0.0  0.0  3.402276  0.514081  0.000000  0.000000  0.000000   0.101716   \n",
       "2     0.0  0.0  3.719712  0.000000  0.536042  0.000000  0.000000   0.000000   \n",
       "3     0.0  0.0  4.116067  0.000000  0.266676  0.435027  0.000000   0.149434   \n",
       "4     0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  56.917328   \n",
       "...   ...  ...       ...       ...       ...       ...       ...        ...   \n",
       "1702  0.0  0.0  3.864935  0.488492  0.000000  0.771563  0.000000   0.000000   \n",
       "1703  0.0  0.0  3.125597  0.048152  0.245986  0.000000  0.073176   0.057343   \n",
       "1704  0.0  0.0  2.337677  0.293424  0.000000  1.872908  0.000000   1.151660   \n",
       "1705  0.0  0.0  3.656493  0.000000  0.011994  0.000000  0.029398   0.190015   \n",
       "1706  0.0  0.0  2.641998  0.000000  0.000000  4.938718  0.000000   0.000000   \n",
       "\n",
       "             8         9  ...  239  240  241  242  243  244  245  246  247  \\\n",
       "0     0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.024690  0.078666  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.030668  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     0.000000  0.196687  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1702  0.844417  0.536116  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1703  0.000000  0.305803  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1704  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1705  0.000000  0.201823  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1706  0.000000  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      label  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "1702      0  \n",
       "1703      0  \n",
       "1704      0  \n",
       "1705      0  \n",
       "1706      0  \n",
       "\n",
       "[1707 rows x 249 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
